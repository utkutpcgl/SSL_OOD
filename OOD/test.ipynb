{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "from utils.test_final import test_all_networks\n",
    "test_all_networks()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as trn\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image as PILImage\n",
    "import yaml\n",
    "\n",
    "# go through rigamaroo to do ...utils.display_results import show_performance\n",
    "if __package__ is None:\n",
    "    import sys\n",
    "    from os import path\n",
    "\n",
    "    sys.path.append(path.dirname(path.dirname(path.abspath(__file__))))\n",
    "    from utils.display_results import show_performance, get_measures, print_measures\n",
    "    import utils.score_calculation as lib\n",
    "\n",
    "\n",
    "# input image size settings\n",
    "with open(\"ft_hyperparameters.yaml\", \"r\") as reader:\n",
    "    HYPS = yaml.safe_load(reader)\n",
    "\n",
    "# Setup\n",
    "batch_size_TEST = HYPS[\"batch_size_TEST\"]  # Energy loss scale.\n",
    "energy_temperature = HYPS[\"energy_temperature\"]  # Energy loss scale.\n",
    "NGPU = 1\n",
    "WORKERS = 4\n",
    "# EG and benchmark details\n",
    "# torch.manual_seed(1)\n",
    "# np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# mean and standard deviation of channels of CIFAR-10 images\n",
    "mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "\n",
    "test_transform = trn.Compose([trn.ToTensor(), trn.Normalize(mean, std)])\n",
    "\n",
    "test_data = dset.CIFAR10('/home/utku/Documents/repos/SSL_OOD/cifar-10', train=False, transform=test_transform)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=batch_size_TEST, shuffle=False,\n",
    "                                          num_workers=WORKERS, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VARIABLES RANDOMLY USED AS GLOBAL, BE CAREFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# /////////////// Detection Prelims ///////////////\n",
    "ood_num_examples = len(test_data) // 5\n",
    "\n",
    "concat = lambda x: np.concatenate(x, axis=0)\n",
    "to_np = lambda x: x.data.cpu().numpy()\n",
    "\n",
    "\n",
    "def get_ood_scores(loader, in_dist=False):\n",
    "    \"\"\"Get scores would be a better name as the method is also used for correct classifications.\"\"\"\n",
    "    _score = [] # The ID data energy scores are stored here.\n",
    "    # The scores below are used to find the error rate at the original in distribution task. \n",
    "    # Number of right/ predictions are used rather than their sofmtax score.\n",
    "    _right_score = []\n",
    "    _wrong_score = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            if batch_idx >= ood_num_examples // batch_size_TEST and in_dist is False:\n",
    "                break\n",
    "\n",
    "            data = data.cuda()\n",
    "\n",
    "            output = ResNet(data)\n",
    "            smax = to_np(F.softmax(output, dim=1))\n",
    "            \n",
    "            _score.append(-to_np((energy_temperature*torch.logsumexp(output / energy_temperature, dim=1))))\n",
    "                \n",
    "\n",
    "            if in_dist:\n",
    "                preds = np.argmax(smax, axis=1)\n",
    "                targets = target.numpy().squeeze()\n",
    "                right_indices = preds == targets\n",
    "                wrong_indices = np.invert(right_indices)\n",
    "                # Calculate the scores, only the lenght of those score lists are used.\n",
    "                _right_score.append(-np.max(smax[right_indices], axis=1))\n",
    "                _wrong_score.append(-np.max(smax[wrong_indices], axis=1))\n",
    "\n",
    "    if in_dist:\n",
    "        return concat(_score).copy(), concat(_right_score).copy(), concat(_wrong_score).copy()\n",
    "    else:\n",
    "        return concat(_score)[:ood_num_examples].copy()\n",
    "\n",
    "in_score, right_score, wrong_score = get_ood_scores(test_loader, in_dist=True) # Only in_score is important here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_right = len(right_score)\n",
    "num_wrong = len(wrong_score)\n",
    "print('Error Rate {:.2f}'.format(100 * num_wrong / (num_wrong + num_right)))\n",
    "\n",
    "# /////////////// Error Detection ///////////////\n",
    "\n",
    "print('\\n\\nError Detection')\n",
    "show_performance(wrong_score, right_score)\n",
    "\n",
    "# /////////////// OOD Detection ///////////////\n",
    "auroc_list, aupr_list, fpr_list = [], [], []\n",
    "\n",
    "\n",
    "def get_and_print_results(ood_loader):\n",
    "\n",
    "    aurocs, auprs, fprs = [], [], []\n",
    "\n",
    "    out_score = get_ood_scores(ood_loader)\n",
    "    measures = get_measures(-in_score, -out_score)\n",
    "    aurocs.append(measures[0]); auprs.append(measures[1]); fprs.append(measures[2])\n",
    "    print(in_score[:3], out_score[:3])\n",
    "    auroc = np.mean(aurocs); aupr = np.mean(auprs); fpr = np.mean(fprs)\n",
    "    auroc_list.append(auroc); aupr_list.append(aupr); fpr_list.append(fpr)\n",
    "    print_measures(auroc, aupr, fpr)\n",
    "\n",
    "\n",
    "# /////////////// Textures ///////////////\n",
    "ood_data = dset.ImageFolder(root=\"/home/utku/Documents/repos/SSL_OOD/dtd-r1.0.1/Describable_Textures_Dataset/images\",\n",
    "                            transform=trn.Compose([trn.Resize(32), trn.CenterCrop(32),\n",
    "                                                   trn.ToTensor(), trn.Normalize(mean, std)]))\n",
    "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=batch_size_TEST, shuffle=True,\n",
    "                                         num_workers=4, pin_memory=True)\n",
    "print('\\n\\nTexture Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "\n",
    "# /////////////// Mean Results ///////////////\n",
    "\n",
    "print('\\n\\nMean Test Results!!!!!')\n",
    "print_measures(np.mean(auroc_list), np.mean(aupr_list), np.mean(fpr_list))\n",
    "\n",
    "# /////////////// OOD Detection of Validation Distributions ///////////////\n",
    "\n",
    "\n",
    "auroc_list, aupr_list, fpr_list = [], [], []\n",
    "\n",
    "# /////////////// Uniform Noise ///////////////\n",
    "\n",
    "dummy_targets = torch.ones(ood_num_examples)\n",
    "ood_data = torch.from_numpy(\n",
    "    np.random.uniform(size=(ood_num_examples, 3, 32, 32),\n",
    "                      low=-1.0, high=1.0).astype(np.float32))\n",
    "ood_data = torch.utils.data.TensorDataset(ood_data, dummy_targets)\n",
    "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=batch_size_TEST, shuffle=True)\n",
    "\n",
    "print('\\n\\nUniform[-1,1] Noise Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "\n",
    "# /////////////// Arithmetic Mean of Images ///////////////\n",
    "\n",
    "ood_data = dset.CIFAR100('/home/utku/Documents/repos/SSL_OOD/cifar-100', train=False, transform=test_transform)\n",
    "\n",
    "\n",
    "\n",
    "class AvgOfPair(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.shuffle_indices = np.arange(len(dataset))\n",
    "        np.random.shuffle(self.shuffle_indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        random_idx = np.random.choice(len(self.dataset))\n",
    "        while random_idx == i:\n",
    "            random_idx = np.random.choice(len(self.dataset))\n",
    "\n",
    "        return self.dataset[i][0] / 2. + self.dataset[random_idx][0] / 2., 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "ood_loader = torch.utils.data.DataLoader(AvgOfPair(ood_data),\n",
    "                                         batch_size=batch_size_TEST, shuffle=True,\n",
    "                                         num_workers=WORKERS, pin_memory=True)\n",
    "\n",
    "print('\\n\\nArithmetic Mean of Random Image Pair Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "\n",
    "# /////////////// Geometric Mean of Images ///////////////\n",
    "\n",
    "ood_data = dset.CIFAR100('/home/utku/Documents/repos/SSL_OOD/cifar-100', train=False, download=True, transform=trn.ToTensor())\n",
    "\n",
    "\n",
    "\n",
    "class GeomMeanOfPair(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.shuffle_indices = np.arange(len(dataset))\n",
    "        np.random.shuffle(self.shuffle_indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        random_idx = np.random.choice(len(self.dataset))\n",
    "        while random_idx == i:\n",
    "            random_idx = np.random.choice(len(self.dataset))\n",
    "\n",
    "        return trn.Normalize(mean, std)(torch.sqrt(self.dataset[i][0] * self.dataset[random_idx][0])), 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "ood_loader = torch.utils.data.DataLoader(\n",
    "    GeomMeanOfPair(ood_data), batch_size=batch_size_TEST, shuffle=True,\n",
    "    num_workers=WORKERS, pin_memory=True)\n",
    "\n",
    "print('\\n\\nGeometric Mean of Random Image Pair Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "# /////////////// Jigsaw Images ///////////////\n",
    "\n",
    "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=batch_size_TEST, shuffle=True,\n",
    "                                         num_workers=WORKERS, pin_memory=True)\n",
    "\n",
    "jigsaw = lambda x: torch.cat((\n",
    "    torch.cat((torch.cat((x[:, 8:16, :16], x[:, :8, :16]), 1),\n",
    "               x[:, 16:, :16]), 2),\n",
    "    torch.cat((x[:, 16:, 16:],\n",
    "               torch.cat((x[:, :16, 24:], x[:, :16, 16:24]), 2)), 2),\n",
    "), 1)\n",
    "\n",
    "ood_loader.dataset.transform = trn.Compose([trn.ToTensor(), jigsaw, trn.Normalize(mean, std)])\n",
    "\n",
    "print('\\n\\nJigsawed Images Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "# /////////////// Speckled Images ///////////////\n",
    "\n",
    "speckle = lambda x: torch.clamp(x + x * torch.randn_like(x), 0, 1)\n",
    "ood_loader.dataset.transform = trn.Compose([trn.ToTensor(), speckle, trn.Normalize(mean, std)])\n",
    "\n",
    "print('\\n\\nSpeckle Noised Images Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "# /////////////// Pixelated Images ///////////////\n",
    "\n",
    "pixelate = lambda x: x.resize((int(32 * 0.2), int(32 * 0.2)), PILImage.BOX).resize((32, 32), PILImage.BOX)\n",
    "ood_loader.dataset.transform = trn.Compose([pixelate, trn.ToTensor(), trn.Normalize(mean, std)])\n",
    "\n",
    "print('\\n\\nPixelate Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "# /////////////// RGB Ghosted/Shifted Images ///////////////\n",
    "\n",
    "rgb_shift = lambda x: torch.cat((x[1:2].index_select(2, torch.LongTensor([i for i in range(32 - 1, -1, -1)])),\n",
    "                                 x[2:, :, :], x[0:1, :, :]), 0)\n",
    "ood_loader.dataset.transform = trn.Compose([trn.ToTensor(), rgb_shift, trn.Normalize(mean, std)])\n",
    "\n",
    "print('\\n\\nRGB Ghosted/Shifted Image Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "# /////////////// Inverted Images ///////////////\n",
    "\n",
    "# not done on all channels to make image ood with higher probability\n",
    "invert = lambda x: torch.cat((x[0:1, :, :], 1 - x[1:2, :, ], 1 - x[2:, :, :],), 0)\n",
    "ood_loader.dataset.transform = trn.Compose([trn.ToTensor(), invert, trn.Normalize(mean, std)])\n",
    "\n",
    "print('\\n\\nInverted Image Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "# /////////////// Mean Results ///////////////\n",
    "\n",
    "print('\\n\\nMean Validation Results')\n",
    "print_measures(np.mean(auroc_list), np.mean(aupr_list), np.mean(fpr_list))\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "1484ded363958018b63f22e3cca0a4db1032bdb5172b1a076544307dcdefb374"
  },
  "kernelspec": {
   "display_name": "Python 3.9.13 ('base')",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
