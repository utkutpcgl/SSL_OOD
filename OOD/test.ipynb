{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import sys\n",
    "import os\n",
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision.transforms as trn\n",
    "import torchvision.datasets as dset\n",
    "import torch.nn.functional as F\n",
    "from PIL import Image as PILImage\n",
    "\n",
    "# go through rigamaroo to do ...utils.display_results import show_performance\n",
    "if __package__ is None:\n",
    "    import sys\n",
    "    from os import path\n",
    "\n",
    "    sys.path.append(path.dirname(path.dirname(path.abspath(__file__))))\n",
    "    from utils.display_results import show_performance, get_measures, print_measures, print_measures_with_std\n",
    "    import utils.score_calculation as lib\n",
    "\n",
    "parser = argparse.ArgumentParser(description='Evaluates a CIFAR OOD Detector',\n",
    "                                 formatter_class=argparse.ArgumentDefaultsHelpFormatter)\n",
    "# Setup\n",
    "parser.add_argument('--test_bs', type=int, default=200)\n",
    "parser.add_argument('--num_to_avg', type=int, default=1, help='Average measures across num_to_avg runs.')\n",
    "parser.add_argument('--validate', '-v', action='store_true', help='Evaluate performance on validation distributions.')\n",
    "parser.add_argument('--use_xent', '-x', action='store_true', help='Use cross entropy scoring instead of the MSP.')\n",
    "parser.add_argument('--method_name', '-m', type=str, default='cifar10_allconv_baseline', help='Method name.')\n",
    "# Loading details\n",
    "parser.add_argument('--layers', default=40, type=int, help='total number of layers')\n",
    "parser.add_argument('--widen-factor', default=2, type=int, help='widen factor')\n",
    "parser.add_argument('--droprate', default=0.3, type=float, help='dropout probability')\n",
    "parser.add_argument('--load', '-l', type=str, default='./snapshots', help='Checkpoint path to resume / test.')\n",
    "parser.add_argument('--ngpu', type=int, default=1, help='0 = CPU.')\n",
    "parser.add_argument('--prefetch', type=int, default=2, help='Pre-fetching threads.')\n",
    "# EG and benchmark details\n",
    "parser.add_argument('--out_as_pos', action='store_true', help='OE define OOD data as positive.')\n",
    "parser.add_argument('--score', default='MSP', type=str, help='score options: MSP|energy')\n",
    "parser.add_argument('--T', default=1., type=float, help='temperature: energy|Odin')\n",
    "parser.add_argument('--noise', type=float, default=0, help='noise for Odin')\n",
    "args = parser.parse_args()\n",
    "print(args)\n",
    "# torch.manual_seed(1)\n",
    "# np.random.seed(1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# mean and standard deviation of channels of CIFAR-10 images\n",
    "mean = [x / 255 for x in [125.3, 123.0, 113.9]]\n",
    "std = [x / 255 for x in [63.0, 62.1, 66.7]]\n",
    "\n",
    "test_transform = trn.Compose([trn.ToTensor(), trn.Normalize(mean, std)])\n",
    "\n",
    "test_data = dset.CIFAR10('../data/cifarpy', train=False, transform=test_transform)\n",
    "num_classes = 10\n",
    "\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(test_data, batch_size=args.test_bs, shuffle=False,\n",
    "                                          num_workers=args.prefetch, pin_memory=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "%run train.ipynb # To import ResNet\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VARIABLES RANDOMLY USED AS GLOBAL, BE CAREFUL"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "%run train.ipynb # To import ResNet\n",
    "# Create model\n",
    "start_epoch = 0\n",
    "# Restore model\n",
    "if args.load != '':\n",
    "    for i in range(1000 - 1, -1, -1):\n",
    "        if 'pretrained' in args.method_name:\n",
    "            subdir = 'pretrained'\n",
    "        elif 'energy_ft' in args.method_name:\n",
    "            subdir = 'energy_ft'\n",
    "        \n",
    "        \n",
    "        model_name = os.path.join(os.path.join(args.load, subdir), args.method_name + '_epoch_' + str(i) + '.pt') \n",
    "        if os.path.isfile(model_name):\n",
    "            ResNet.load_state_dict(torch.load(model_name))\n",
    "            print('Model restored! Epoch:', i)\n",
    "            start_epoch = i + 1\n",
    "            break\n",
    "    if start_epoch == 0:\n",
    "        assert False, \"could not resume \"+model_name\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ResNet.eval()\n",
    "\n",
    "if args.ngpu > 1:\n",
    "    ResNet = torch.nn.DataParallel(ResNet, device_ids=list(range(args.ngpu)))\n",
    "\n",
    "if args.ngpu > 0:\n",
    "    ResNet.cuda()\n",
    "    # torch.cuda.manual_seed(1)\n",
    "\n",
    "cudnn.benchmark = True  # fire on all cylinders\n",
    "\n",
    "# /////////////// Detection Prelims ///////////////\n",
    "\n",
    "ood_num_examples = len(test_data) // 5\n",
    "expected_ap = ood_num_examples / (ood_num_examples + len(test_data))\n",
    "\n",
    "concat = lambda x: np.concatenate(x, axis=0)\n",
    "to_np = lambda x: x.data.cpu().numpy()\n",
    "\n",
    "\n",
    "def get_ood_scores(loader, in_dist=False):\n",
    "    _score = [] # The ID data energy scores are stored here.\n",
    "    # The scores below are used to find the error rate at the original in distribution task. \n",
    "    # Number of right/ predictions are used rather than their sofmtax score.\n",
    "    _right_score = []\n",
    "    _wrong_score = []\n",
    "\n",
    "    with torch.no_grad():\n",
    "        for batch_idx, (data, target) in enumerate(loader):\n",
    "            if batch_idx >= ood_num_examples // args.test_bs and in_dist is False:\n",
    "                break\n",
    "\n",
    "            data = data.cuda()\n",
    "\n",
    "            output = ResNet(data)\n",
    "            smax = to_np(F.softmax(output, dim=1))\n",
    "            \n",
    "            _score.append(-to_np((args.T*torch.logsumexp(output / args.T, dim=1))))\n",
    "                \n",
    "\n",
    "            if in_dist:\n",
    "                preds = np.argmax(smax, axis=1)\n",
    "                targets = target.numpy().squeeze()\n",
    "                right_indices = preds == targets\n",
    "                wrong_indices = np.invert(right_indices)\n",
    "                # Calculate the scores, only the lenght of those score lists are used.\n",
    "                _right_score.append(-np.max(smax[right_indices], axis=1))\n",
    "                _wrong_score.append(-np.max(smax[wrong_indices], axis=1))\n",
    "\n",
    "    if in_dist:\n",
    "        return concat(_score).copy(), concat(_right_score).copy(), concat(_wrong_score).copy()\n",
    "    else:\n",
    "        return concat(_score)[:ood_num_examples].copy()\n",
    "\n",
    "in_score, right_score, wrong_score = get_ood_scores(test_loader, in_dist=True) # Only in_score is important here.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluate Results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "num_right = len(right_score)\n",
    "num_wrong = len(wrong_score)\n",
    "print('Error Rate {:.2f}'.format(100 * num_wrong / (num_wrong + num_right)))\n",
    "\n",
    "# /////////////// End Detection Prelims ///////////////\n",
    "\n",
    "print('\\nUsing CIFAR-10 as typical data') if num_classes == 10 else print('\\nUsing CIFAR-100 as typical data')\n",
    "\n",
    "# /////////////// Error Detection ///////////////\n",
    "\n",
    "print('\\n\\nError Detection')\n",
    "show_performance(wrong_score, right_score, method_name=args.method_name)\n",
    "\n",
    "# /////////////// OOD Detection ///////////////\n",
    "auroc_list, aupr_list, fpr_list = [], [], []\n",
    "\n",
    "\n",
    "def get_and_print_results(ood_loader, num_to_avg=args.num_to_avg):\n",
    "\n",
    "    aurocs, auprs, fprs = [], [], []\n",
    "\n",
    "    for _ in range(num_to_avg):\n",
    "        \n",
    "        out_score = get_ood_scores(ood_loader)\n",
    "        measures = get_measures(-in_score, -out_score)\n",
    "        aurocs.append(measures[0]); auprs.append(measures[1]); fprs.append(measures[2])\n",
    "    print(in_score[:3], out_score[:3])\n",
    "    auroc = np.mean(aurocs); aupr = np.mean(auprs); fpr = np.mean(fprs)\n",
    "    auroc_list.append(auroc); aupr_list.append(aupr); fpr_list.append(fpr)\n",
    "\n",
    "    if num_to_avg >= 5:\n",
    "        print_measures_with_std(aurocs, auprs, fprs, args.method_name)\n",
    "    else:\n",
    "        print_measures(auroc, aupr, fpr, args.method_name)\n",
    "\n",
    "\n",
    "# /////////////// Textures ///////////////\n",
    "ood_data = dset.ImageFolder(root=\"/home/utku/Documents/repos/SSL_OOD/dtd-r1.0.1/Describable_Textures_Dataset/images\",\n",
    "                            transform=trn.Compose([trn.Resize(32), trn.CenterCrop(32),\n",
    "                                                   trn.ToTensor(), trn.Normalize(mean, std)]))\n",
    "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=args.test_bs, shuffle=True,\n",
    "                                         num_workers=4, pin_memory=True)\n",
    "print('\\n\\nTexture Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "\n",
    "# /////////////// Mean Results ///////////////\n",
    "\n",
    "print('\\n\\nMean Test Results!!!!!')\n",
    "print_measures(np.mean(auroc_list), np.mean(aupr_list), np.mean(fpr_list), method_name=args.method_name)\n",
    "\n",
    "# /////////////// OOD Detection of Validation Distributions ///////////////\n",
    "\n",
    "if args.validate is False:\n",
    "    exit()\n",
    "\n",
    "auroc_list, aupr_list, fpr_list = [], [], []\n",
    "\n",
    "# /////////////// Uniform Noise ///////////////\n",
    "\n",
    "dummy_targets = torch.ones(ood_num_examples * args.num_to_avg)\n",
    "ood_data = torch.from_numpy(\n",
    "    np.random.uniform(size=(ood_num_examples * args.num_to_avg, 3, 32, 32),\n",
    "                      low=-1.0, high=1.0).astype(np.float32))\n",
    "ood_data = torch.utils.data.TensorDataset(ood_data, dummy_targets)\n",
    "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=args.test_bs, shuffle=True)\n",
    "\n",
    "print('\\n\\nUniform[-1,1] Noise Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "\n",
    "# /////////////// Arithmetic Mean of Images ///////////////\n",
    "\n",
    "if 'cifar10_' in args.method_name:\n",
    "    ood_data = dset.CIFAR100('../data/vision-greg/cifarpy', train=False, transform=test_transform)\n",
    "else:\n",
    "    ood_data = dset.CIFAR10('../data/vision-greg/cifarpy', train=False, transform=test_transform)\n",
    "\n",
    "\n",
    "class AvgOfPair(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.shuffle_indices = np.arange(len(dataset))\n",
    "        np.random.shuffle(self.shuffle_indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        random_idx = np.random.choice(len(self.dataset))\n",
    "        while random_idx == i:\n",
    "            random_idx = np.random.choice(len(self.dataset))\n",
    "\n",
    "        return self.dataset[i][0] / 2. + self.dataset[random_idx][0] / 2., 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "ood_loader = torch.utils.data.DataLoader(AvgOfPair(ood_data),\n",
    "                                         batch_size=args.test_bs, shuffle=True,\n",
    "                                         num_workers=args.prefetch, pin_memory=True)\n",
    "\n",
    "print('\\n\\nArithmetic Mean of Random Image Pair Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "\n",
    "# /////////////// Geometric Mean of Images ///////////////\n",
    "\n",
    "if 'cifar10_' in args.method_name:\n",
    "    ood_data = dset.CIFAR100('../data/vision-greg/cifarpy', train=False, transform=trn.ToTensor())\n",
    "else:\n",
    "    ood_data = dset.CIFAR10('../data/vision-greg/cifarpy', train=False, transform=trn.ToTensor())\n",
    "\n",
    "\n",
    "class GeomMeanOfPair(torch.utils.data.Dataset):\n",
    "    def __init__(self, dataset):\n",
    "        self.dataset = dataset\n",
    "        self.shuffle_indices = np.arange(len(dataset))\n",
    "        np.random.shuffle(self.shuffle_indices)\n",
    "\n",
    "    def __getitem__(self, i):\n",
    "        random_idx = np.random.choice(len(self.dataset))\n",
    "        while random_idx == i:\n",
    "            random_idx = np.random.choice(len(self.dataset))\n",
    "\n",
    "        return trn.Normalize(mean, std)(torch.sqrt(self.dataset[i][0] * self.dataset[random_idx][0])), 0\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.dataset)\n",
    "\n",
    "\n",
    "ood_loader = torch.utils.data.DataLoader(\n",
    "    GeomMeanOfPair(ood_data), batch_size=args.test_bs, shuffle=True,\n",
    "    num_workers=args.prefetch, pin_memory=True)\n",
    "\n",
    "print('\\n\\nGeometric Mean of Random Image Pair Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "# /////////////// Jigsaw Images ///////////////\n",
    "\n",
    "ood_loader = torch.utils.data.DataLoader(ood_data, batch_size=args.test_bs, shuffle=True,\n",
    "                                         num_workers=args.prefetch, pin_memory=True)\n",
    "\n",
    "jigsaw = lambda x: torch.cat((\n",
    "    torch.cat((torch.cat((x[:, 8:16, :16], x[:, :8, :16]), 1),\n",
    "               x[:, 16:, :16]), 2),\n",
    "    torch.cat((x[:, 16:, 16:],\n",
    "               torch.cat((x[:, :16, 24:], x[:, :16, 16:24]), 2)), 2),\n",
    "), 1)\n",
    "\n",
    "ood_loader.dataset.transform = trn.Compose([trn.ToTensor(), jigsaw, trn.Normalize(mean, std)])\n",
    "\n",
    "print('\\n\\nJigsawed Images Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "# /////////////// Speckled Images ///////////////\n",
    "\n",
    "speckle = lambda x: torch.clamp(x + x * torch.randn_like(x), 0, 1)\n",
    "ood_loader.dataset.transform = trn.Compose([trn.ToTensor(), speckle, trn.Normalize(mean, std)])\n",
    "\n",
    "print('\\n\\nSpeckle Noised Images Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "# /////////////// Pixelated Images ///////////////\n",
    "\n",
    "pixelate = lambda x: x.resize((int(32 * 0.2), int(32 * 0.2)), PILImage.BOX).resize((32, 32), PILImage.BOX)\n",
    "ood_loader.dataset.transform = trn.Compose([pixelate, trn.ToTensor(), trn.Normalize(mean, std)])\n",
    "\n",
    "print('\\n\\nPixelate Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "# /////////////// RGB Ghosted/Shifted Images ///////////////\n",
    "\n",
    "rgb_shift = lambda x: torch.cat((x[1:2].index_select(2, torch.LongTensor([i for i in range(32 - 1, -1, -1)])),\n",
    "                                 x[2:, :, :], x[0:1, :, :]), 0)\n",
    "ood_loader.dataset.transform = trn.Compose([trn.ToTensor(), rgb_shift, trn.Normalize(mean, std)])\n",
    "\n",
    "print('\\n\\nRGB Ghosted/Shifted Image Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "# /////////////// Inverted Images ///////////////\n",
    "\n",
    "# not done on all channels to make image ood with higher probability\n",
    "invert = lambda x: torch.cat((x[0:1, :, :], 1 - x[1:2, :, ], 1 - x[2:, :, :],), 0)\n",
    "ood_loader.dataset.transform = trn.Compose([trn.ToTensor(), invert, trn.Normalize(mean, std)])\n",
    "\n",
    "print('\\n\\nInverted Image Detection')\n",
    "get_and_print_results(ood_loader)\n",
    "\n",
    "# /////////////// Mean Results ///////////////\n",
    "\n",
    "print('\\n\\nMean Validation Results')\n",
    "print_measures(np.mean(auroc_list), np.mean(aupr_list), np.mean(fpr_list), method_name=args.method_name)\n"
   ]
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
  },
  "kernelspec": {
   "display_name": "Python 3.6.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
